\chapter{Desarrollo}

\section{Análisis previo}
El punto de partida de este proyecto fue el interés en explorar las aplicaciones prácticas de la inteligencia artificial generativa en un formato físico interactuable, con el fin de crear un dispositivo que genere cercanía y acompañamiento al usuario.

El primer concepto consistía en utilizar un hardware disponible en la institución: una cabeza robótica estática. La idea era dotar a esta cabeza de capacidades conversacionales, aprovechando su estructura existente para simular interacción humana (movimiento de ojos o boca).

Sin embargo, tras un análisis preliminar, se descartó la idea, y se prefirió crear un hardware de cero, ya que entregaría mayor libertad de diseño e integración. Esto llevó entonces hacía un concepto nuevo: un prototipo de robot móvil y compacto.

Esta nueva dirección se eligió por dos ventajas estratégicas:

    \begin{enumerate}
        \item \textbf{Simplicidad de integración:} Aunque la movilidad añade el desafío de crear un sistema de navegación, diseñar un chasis propio desde cero simplifica enormemente la integración y cohesión de los componentes que se quisieran utilizar, ya que no tienen que obligatoriamente adaptarse a un sistema pre existente.

        \item \textbf{Mayor Atractivo e Interacción:} Se determinó que un robot capaz de moverse por la habitación y reaccionar físicamente a su entorno sería percibido por el público como un dispositivo más dinámico y, en definitiva, más atractivo y cercano como "compañero", cumpliendo así el objetivo inicial del proyecto de una forma más efectiva.
    \end{enumerate}

    \subsection{Módulos del prototipo}

    Una vez la idea general definida, fue fundamental realizar un análisis de los componentes necesarios para el funcionamiento del prototipo. Para un desarrollo en paralelo y modular, se dividió el robot en dos módulos principales e inicialmente independientes entre sí, con el objetivo de ser conectados una vez cada uno estuviese lo suficientemente avanzado:

    \begin{enumerate}
        \item \textbf{Movimiento:} Este módulo englobaría toda la locomoción física del robot. Se compondría de un chasis estructural, un sistema de ruedas impulsadas por motores y un sensor ultrasónico para la detección de obstáculos. Para controlar el movimiento se escogió el microcontrolador Arduino Uno, debido a su simplicidad de programación y su disponibilidad en el departamento.

        \item \textbf{Comunicacion:} Modulo en donde residiría todo lo relacionado con la comunicacion con el usuario. Se determinó inicialmente el levantar localmente una LLM en un Raspberry PI 5, debido a su diseño compacto y potenica. Sin embargo, esta idea fue descartada rapidamente debido a que los modelos utilizados representaban una carga muy grande para el dispositivo. En ella además se conectarían los dispositivos de entrada y salida. Se determinó que la forma de comunicación más cercana y amigable sería a través de voz.
        Como solucion al problema de la potencia, se decidio utilizar una API local para la comunicacion con la IA, utilizando el Raspberry PI como un intermediario entre el usuario y el modelo de lenguaje alojado en otra maquina utilizada como servidor.
    \end{enumerate}

    \subsection{Diseño}

    Una vez la funcionalidad determinada, se analizó la presentación visual del prototipo. Por las características de los componentes y los recursos limitados, se necesitaba una carcasa ligera y a su misma vez accesible. Se optó entonces por crear o buscar un modelo para imprimir en 3D, lo que entonces implicó que el diseño además debiese ser simple para evitar problemas con el filamento o de ensamblaje.

    Finalmente se optó por una carcasa completamente cúbica, ya que no solo resulta sumamente fácil de ensamblar, sino que además le da al robot una apariencia agradable. Este diseño entonces se bosquejó, para luego ser trabajado y adaptado en un modelo 3D por Nicolás Poblete, quien durante todo el transcurso del proyecto prestó apoyo en lo que es diseño e impresión del prototipo.


\newpage
\section{Movimiento}

Para el movimiento del robot se tomó como base un proyecto previo, el cual consistía en un auto a control remoto por bluetooth. Este contenía dos motores, 4 ruedas, un servo para las ruedas delanteras, un Arduino Uno para controlar los motores, baterías y un puente H L293D, componentes que fueron reutilizados en el presente prototipo.

\subsection{Movimiento hacia adelante y hacia atrás}

Para lograr realizar un sistema de ruedas y motores que se muevan hacía una dirección fija, se utilizaron los siguientes componentes

\begin{itemize}
    \item \textbf{Arduino Uno:} Microcontrolador encargado de la lógica, dando la señal de que si se debe avanzar hacia adelante o hacia atrás.
    \item \textbf{Puente H L293D}: Chip que funciona como driver para motores. Su función es controlar la velocidad de los motores.
    \item \textbf{2 Motores DC:} Estos motores son los encargados de hacer que las ruedas traseras giren, funcionando a comando del puente H.
    \item \textbf{4 Ruedas}
    \item \textbf{Protoboard y jumpers:}
\end{itemize}

\subsection{Detección de obstáculos}


\subsection{Movimiento autónomo}

\newpage

\section{Comunicacion}
Como se establecio previamente en el analisis del problema, se decidio utilizar un rsapberry PI como el nucleo del modulo de comunicacion. Este dispositivo se encargaría de recibir la entrada de audio del usuario, enviarla a un modelo de lenguaje alojado en un servidor externo, y luego reproducir la respuesta generada a través de un altavoz. Este flujo de trabajo suena simple, pero en la practica implico una serie de desafíos técnicos y decisiones de diseño que seran detallados en esta sección.

\subsection{Arquitectura del sistema}
El sistema de comunicación se diseñó adaptando una arquitectura cliente-servidor\footnote{Modelo de aplicación que distribuye las tareas entre los proveedores de recursos o servicios y solicitantes de servicios. \cite{ibm_clientserver}}. El Raspberry Pi actua como cliente, mientras que una maquina externa con mayor capacidad de procesamiento aloja el modelo de lenguaje y actua como servidor. Esta separación permite que el Raspberry Pi maneje las tareas de entrada y salida de audio, mientras que el servidor se encarga del procesamiento intensivo requerido por el modelo de lenguaje.


En la figura \ref{fig:diag_com} se muestra un diagrama de funcionamiento entre los componentes principales del sistema de comunicación.

\texttt{client.py} es el script principal que corre en el Raaspberry PI. Este se encarga de detectar constantemente si el usuario ha emitido una entrada de voz especifica o Wake Word (en este caso "Hey Bot"). Al detectar esta entrada, el script graba la voz del usuario durante un periodo de  tiempo y la envía al servidor a través de una solicitud HTTP POST. Esto se realiza utilizando la libreria \texttt{Por}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{Fig/diagrama_api.pdf}
    \caption{Diagrama de comunicacion Servidor-Cliente}
    \label{fig:diag_com}
\end{figure}

\section{Comunicación Raspberry-Arduino}

\section{Diseño}
